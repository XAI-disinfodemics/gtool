import re
import random
import requests
from lxml import html
from time import sleep
from gtool.settings import GOOGLE_SEARCH, NEWS_CARD_XPATH
from gtool.modules.base import BaseEngine
from gtool.logs import setup_logging


_logger = setup_logging(__name__)


class DuckDuckGoEngine(BaseEngine):
    name = "DuckDuckGo"
    help = "Use the DuckDuckGo search engine to scrape news."

    def __init__(self, **kwargs):
        """ * -> force all arguments afterwards are keyword-only
        """
        headers = {
            'authority': 'duckduckgo.com',
            'accept': 'application/json, text/javascript, */*; q=0.01',
            'accept-language': 'es-ES,es;q=0.9',
        }
        super().__init__(
            search_url="https://duckduckgo.com/news.js", 
            headers=headers,
            **kwargs
        )

    @classmethod
    def _cli_setup_parser(cls, subparser):
        """
        Arguments
        ----------
        lang: string, optional
            RFC 5646 lang code to force Google to return results only in a specific language 
            Available lang codes = ['au-en', 'es-es', 'wt-wt', 'ar-es', 'at-de', 'be-fr', 'be-nl', 
                'br-pt', 'bg-bg', 'ca-en', 'ca-fr', 'ct-ca', 'cl-es', 'cn-zh', 
                'co-es', 'hr-hr', 'cz-cs', 'dk-da', 'ee-et', 'fi-fi', 'fr-fr', 
                'de-de', 'gr-el', 'hk-tzh', 'hu-hu', 'is-is', 'in-en', 'id-en', 
                'ie-en', 'il-en', 'it-it', 'jp-jp', 'kr-kr', 'lv-lv', 'lt-lt', 
                'my-en', 'mx-es', 'nl-nl', 'nz-en', 'no-no', 'pk-en', 'pe-es', 
                'ph-en', 'pl-pl', 'pt-pt', 'ro-ro', 'ru-ru', 'xa-ar', 'sg-en', 
                'sk-sk', 'sl-sl', 'za-en', 'es-ca', 'se-sv', 'ch-de', 'ch-fr', 
                'tw-tzh', 'th-en', 'tr-tr', 'us-en', 'us-es', 'ua-uk', 'uk-en', 
                'vn-en'
            ]
        """
        super()._cli_setup_parser(subparser) # Common parameters between engines like time or range 
        subparser.add_argument(
            '--lang', 
            dest='lang',
            choices=['au-en', 'es-es', 'wt-wt', 'ar-es', 'at-de', 'be-fr', 'be-nl', 
                'br-pt', 'bg-bg', 'ca-en', 'ca-fr', 'ct-ca', 'cl-es', 'cn-zh', 
                'co-es', 'hr-hr', 'cz-cs', 'dk-da', 'ee-et', 'fi-fi', 'fr-fr', 
                'de-de', 'gr-el', 'hk-tzh', 'hu-hu', 'is-is', 'in-en', 'id-en', 
                'ie-en', 'il-en', 'it-it', 'jp-jp', 'kr-kr', 'lv-lv', 'lt-lt', 
                'my-en', 'mx-es', 'nl-nl', 'nz-en', 'no-no', 'pk-en', 'pe-es', 
                'ph-en', 'pl-pl', 'pt-pt', 'ro-ro', 'ru-ru', 'xa-ar', 'sg-en', 
                'sk-sk', 'sl-sl', 'za-en', 'es-ca', 'se-sv', 'ch-de', 'ch-fr', 
                'tw-tzh', 'th-en', 'tr-tr', 'us-en', 'us-es', 'ua-uk', 'uk-en', 
                'vn-en'
            ],
            default='es-es',
            help="""Force Duckduckgo to return results only in a specific language (It only accept some coutry-lang codes from RFC 5646).
            """
        )

    @classmethod
    def _cli_from_args(cls, args):
        return cls._cli_filter_args(
            args, 
            lang=args.lang,
        )

    def _initialize_search(self, session, query):
        
        # Simple requests to extract vqd (unique identifier associated with the search) generated by DDG
        response = session.get(
            'https://duckduckgo.com/', 
            params={'q': query}, 
            headers=self.headers
        )
        vqd_obj = re.search(r'vqd=([\d-]+)\&', response.text, re.M | re.I)

        # Conf date filters
        df = ''
        if self.time:
            df += f'{self.time}'
        elif self.range:
            start_date = self.range[0].strftime("%Y-%m-%d") if self.range[0] else ''
            end_date = self.range[1].strftime("%Y-%m-%d") if self.range[1] else ''
            df += f'{start_date}..{end_date}'
            print(df)

        return {
            'l': self.lang, # Language 
            'o': 'json',
            'noamp': '1', # disable the Accelerated Mobile Pages
            'q': query,
            'vqd': vqd_obj.group(1),
            'p': '-2', # Secure search: -2 deactivated | None Moderate | 1 extrict
            'df': df,
        }

    def _extract_data(self, response, count, page):
        """ Receive a 200 status_code response from the search engine
        """
        return [
            {
                "url": item["url"].strip().lower(), 
                "position": index+1+count,
                "page": page+1
            }
            for index, item in enumerate(response.json().get("results", []))
            if "url" in item
        ]
